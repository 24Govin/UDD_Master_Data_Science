{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo predictivo (Espacial) de siniestros en las calles de Santiago\n",
    "**Model will be split in train/test (80%/20%), using 2013-2017 Dataset and Validated with 2018 Dataset**\n",
    "- UDD - MDS18 - BDA\n",
    "- Final Delivery \n",
    "- 41__Final_Geo_Project_PySpark_MLib_XGBoost_Model_Gr100_dataset-2013-17\n",
    "- 09 August 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running dataset created from 2013 to 2017 as df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed based on:\n",
    "- Big Data Analytics, Oscar Peredo \n",
    "- [PySpark ML and XGBoost full integration tested on the Kaggle Titanic dataset](https://towardsdatascience.com/pyspark-and-xgboost-integration-tested-on-the-kaggle-titanic-dataset-4e75a568bdb)\n",
    "- [Machine Learning with PySpark and MLlib â€” Solving a Binary Classification Problem](https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa)\n",
    "- [Build an end-to-end Machine Learning Model with MLlib in pySpark.](https://towardsdatascience.com/build-an-end-to-end-machine-learning-model-with-mllib-in-pyspark-4917bdf289c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminar Installations\n",
    "\n",
    "- Download the XGBoost jars - The python code will need two scala jars dependencies in order to work. You can download them directly from maven:<br>\n",
    "[xgboost4j]( https://mvnrepository.com/artifact/ml.dmlc/xgboost4j/0.72?source=post_page---------------------------)<br>\n",
    "[xgboost4j-spark](https://mvnrepository.com/artifact/ml.dmlc/xgboost4j-spark/0.72?source=post_page---------------------------)\n",
    "<br><br>\n",
    "- Download the PySpark XGBoost code:<br>\n",
    "[PySpark XGBoost](https://github.com/dmlc/xgboost/files/2161553/sparkxgb.zip?source=post_page---------------------------)\n",
    "<br><br>\n",
    "- FindSpark: PySpark isn't on sys.path by default, but it can be used as a regular library. This can be addressed by either symlinking pyspark into your site-packages, or adding pyspark to sys.path at runtime, as done by findspark.<br>\n",
    "[findspark](https://github.com/minrk/findspark)<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:02.978392Z",
     "start_time": "2019-08-03T17:32:02.973008Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_num_cat_features(df):\n",
    "    cat_cols = [item[0] for item in df.dtypes if item[1].startswith('string')]\n",
    "    print(str(len(cat_cols)) + '  categorical features')\n",
    "\n",
    "    num_cols = [\n",
    "        item[0] for item in df.dtypes\n",
    "        if item[1].startswith('int') | item[1].startswith('double')\n",
    "    ][1:]\n",
    "    print(str(len(num_cols)) + '  numerical features')\n",
    "    return num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and pySpark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:23.356718Z",
     "start_time": "2019-08-03T17:32:23.354058Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:25.743699Z",
     "start_time": "2019-08-03T17:32:25.257655Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:27.191326Z",
     "start_time": "2019-08-03T17:32:27.181481Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:28.625159Z",
     "start_time": "2019-08-03T17:32:28.363854Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from sparkxgb import XGBoostEstimator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.sql.functions import rank, sum, col, mean, round, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:36.265872Z",
     "start_time": "2019-08-03T17:32:33.103220Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PySpark XGBOOST Grid 100m Data Siniestros 2013-2017\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:38.641328Z",
     "start_time": "2019-08-03T17:32:38.599652Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"./sparkxgb/sparkxgb.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Generated from Notebook: \n",
    "- 30_Sprint_IV_Geo_Project_Final Datasets_Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:43.502244Z",
     "start_time": "2019-08-03T17:32:43.370208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCONASET\u001b[m\u001b[m                              geo_stgo_100_crash_test_dataset.csv\r\n",
      "\u001b[34mOSM_Chile\u001b[m\u001b[m                            geo_stgo_100_crash_train_dataset.csv\r\n",
      "final_test_dataset_grid_100.csv      geo_stgo_100_estatic_dataset.csv\r\n",
      "final_train_dataset_grid_100.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:32:58.305909Z",
     "start_time": "2019-08-03T17:32:55.264435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      " |-- bank: integer (nullable = true)\n",
      " |-- bench: integer (nullable = true)\n",
      " |-- beverages: integer (nullable = true)\n",
      " |-- bus_stop: integer (nullable = true)\n",
      " |-- bus_stop_100: integer (nullable = true)\n",
      " |-- cafe: integer (nullable = true)\n",
      " |-- convenience: integer (nullable = true)\n",
      " |-- convenience_100: integer (nullable = true)\n",
      " |-- convenience_200: integer (nullable = true)\n",
      " |-- crossing: integer (nullable = true)\n",
      " |-- crossing_100: integer (nullable = true)\n",
      " |-- fast_food: integer (nullable = true)\n",
      " |-- fast_food_100: integer (nullable = true)\n",
      " |-- fast_food_200: integer (nullable = true)\n",
      " |-- fuel: integer (nullable = true)\n",
      " |-- intercect: integer (nullable = true)\n",
      " |-- kindergarten: integer (nullable = true)\n",
      " |-- motorway_junction: integer (nullable = true)\n",
      " |-- parking: integer (nullable = true)\n",
      " |-- parking_bicycle: integer (nullable = true)\n",
      " |-- pharmacy: integer (nullable = true)\n",
      " |-- railway_station: integer (nullable = true)\n",
      " |-- railway_station_100: integer (nullable = true)\n",
      " |-- restaurant: integer (nullable = true)\n",
      " |-- restaurant_100: integer (nullable = true)\n",
      " |-- school: integer (nullable = true)\n",
      " |-- school_100: integer (nullable = true)\n",
      " |-- school_200: integer (nullable = true)\n",
      " |-- stop: integer (nullable = true)\n",
      " |-- stop_100: integer (nullable = true)\n",
      " |-- taxi: integer (nullable = true)\n",
      " |-- traffic_signals: integer (nullable = true)\n",
      " |-- traffic_signals_100: integer (nullable = true)\n",
      " |-- turning_circle: integer (nullable = true)\n",
      " |-- ATROPELLO_100: integer (nullable = true)\n",
      " |-- ATROPELLO_200: integer (nullable = true)\n",
      " |-- CAIDA_100: integer (nullable = true)\n",
      " |-- CAIDA_200: integer (nullable = true)\n",
      " |-- CHOQUE_100: integer (nullable = true)\n",
      " |-- CHOQUE_200: integer (nullable = true)\n",
      " |-- COLISION_100: integer (nullable = true)\n",
      " |-- COLISION_200: integer (nullable = true)\n",
      " |-- INCENDIO_100: integer (nullable = true)\n",
      " |-- INCENDIO_200: integer (nullable = true)\n",
      " |-- OTRO TIPO_100: integer (nullable = true)\n",
      " |-- OTRO TIPO_200: integer (nullable = true)\n",
      " |-- SEV_Index_100: double (nullable = true)\n",
      " |-- SEV_Index_200: double (nullable = true)\n",
      " |-- VOLCADURA_100: integer (nullable = true)\n",
      " |-- VOLCADURA_200: integer (nullable = true)\n",
      " |-- SINIESTRO: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../data/final_train_dataset_grid_100.csv',\n",
    "                    header=True,\n",
    "                    inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying dataset balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:33:28.184999Z",
     "start_time": "2019-08-03T17:33:28.181412Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  categorical features\n",
      "54  numerical features\n"
     ]
    }
   ],
   "source": [
    "# now let's see how many categorical and numerical features we have:\n",
    "num_cols, cat_cols = find_num_cat_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:33:30.689625Z",
     "start_time": "2019-08-03T17:33:29.676329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINIESTRO</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>45450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SINIESTRO  count\n",
       "0          1  17579\n",
       "1          0  45450"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('SINIESTRO').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`There is an imbalanced ratio of (0.72 and 0.28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Verify numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:23.292785Z",
     "start_time": "2019-08-03T17:35:23.288077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'Y',\n",
       " 'bank',\n",
       " 'bench',\n",
       " 'beverages',\n",
       " 'bus_stop',\n",
       " 'bus_stop_100',\n",
       " 'cafe',\n",
       " 'convenience',\n",
       " 'convenience_100',\n",
       " 'convenience_200',\n",
       " 'crossing',\n",
       " 'crossing_100',\n",
       " 'fast_food',\n",
       " 'fast_food_100',\n",
       " 'fast_food_200',\n",
       " 'fuel',\n",
       " 'intercect',\n",
       " 'kindergarten',\n",
       " 'motorway_junction',\n",
       " 'parking',\n",
       " 'parking_bicycle',\n",
       " 'pharmacy',\n",
       " 'railway_station',\n",
       " 'railway_station_100',\n",
       " 'restaurant',\n",
       " 'restaurant_100',\n",
       " 'school',\n",
       " 'school_100',\n",
       " 'school_200',\n",
       " 'stop',\n",
       " 'stop_100',\n",
       " 'taxi',\n",
       " 'traffic_signals',\n",
       " 'traffic_signals_100',\n",
       " 'turning_circle',\n",
       " 'ATROPELLO_100',\n",
       " 'ATROPELLO_200',\n",
       " 'CAIDA_100',\n",
       " 'CAIDA_200',\n",
       " 'CHOQUE_100',\n",
       " 'CHOQUE_200',\n",
       " 'COLISION_100',\n",
       " 'COLISION_200',\n",
       " 'INCENDIO_100',\n",
       " 'INCENDIO_200',\n",
       " 'OTRO TIPO_100',\n",
       " 'OTRO TIPO_200',\n",
       " 'SEV_Index_100',\n",
       " 'SEV_Index_200',\n",
       " 'VOLCADURA_100',\n",
       " 'VOLCADURA_200']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericCols = num_cols[1:-1] # Taking out id and Target variable\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:28.918012Z",
     "start_time": "2019-08-03T17:35:28.915848Z"
    }
   },
   "outputs": [],
   "source": [
    "categoricalColumns = cat_cols\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category Indexing, One-Hot Encoding and VectorAssembler - a feature transformer that merges multiple columns into a vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:32.048187Z",
     "start_time": "2019-08-03T17:35:32.021952Z"
    }
   },
   "outputs": [],
   "source": [
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol,\n",
    "                                  outputCol=categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "label_stringIdx = StringIndexer(inputCol='SINIESTRO', outputCol='label')\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "# Assemble the columns into a feature vector\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:36.184774Z",
     "start_time": "2019-08-03T17:35:35.466547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      " |-- bank: integer (nullable = true)\n",
      " |-- bench: integer (nullable = true)\n",
      " |-- beverages: integer (nullable = true)\n",
      " |-- bus_stop: integer (nullable = true)\n",
      " |-- bus_stop_100: integer (nullable = true)\n",
      " |-- cafe: integer (nullable = true)\n",
      " |-- convenience: integer (nullable = true)\n",
      " |-- convenience_100: integer (nullable = true)\n",
      " |-- convenience_200: integer (nullable = true)\n",
      " |-- crossing: integer (nullable = true)\n",
      " |-- crossing_100: integer (nullable = true)\n",
      " |-- fast_food: integer (nullable = true)\n",
      " |-- fast_food_100: integer (nullable = true)\n",
      " |-- fast_food_200: integer (nullable = true)\n",
      " |-- fuel: integer (nullable = true)\n",
      " |-- intercect: integer (nullable = true)\n",
      " |-- kindergarten: integer (nullable = true)\n",
      " |-- motorway_junction: integer (nullable = true)\n",
      " |-- parking: integer (nullable = true)\n",
      " |-- parking_bicycle: integer (nullable = true)\n",
      " |-- pharmacy: integer (nullable = true)\n",
      " |-- railway_station: integer (nullable = true)\n",
      " |-- railway_station_100: integer (nullable = true)\n",
      " |-- restaurant: integer (nullable = true)\n",
      " |-- restaurant_100: integer (nullable = true)\n",
      " |-- school: integer (nullable = true)\n",
      " |-- school_100: integer (nullable = true)\n",
      " |-- school_200: integer (nullable = true)\n",
      " |-- stop: integer (nullable = true)\n",
      " |-- stop_100: integer (nullable = true)\n",
      " |-- taxi: integer (nullable = true)\n",
      " |-- traffic_signals: integer (nullable = true)\n",
      " |-- traffic_signals_100: integer (nullable = true)\n",
      " |-- turning_circle: integer (nullable = true)\n",
      " |-- ATROPELLO_100: integer (nullable = true)\n",
      " |-- ATROPELLO_200: integer (nullable = true)\n",
      " |-- CAIDA_100: integer (nullable = true)\n",
      " |-- CAIDA_200: integer (nullable = true)\n",
      " |-- CHOQUE_100: integer (nullable = true)\n",
      " |-- CHOQUE_200: integer (nullable = true)\n",
      " |-- COLISION_100: integer (nullable = true)\n",
      " |-- COLISION_200: integer (nullable = true)\n",
      " |-- INCENDIO_100: integer (nullable = true)\n",
      " |-- INCENDIO_200: integer (nullable = true)\n",
      " |-- OTRO TIPO_100: integer (nullable = true)\n",
      " |-- OTRO TIPO_200: integer (nullable = true)\n",
      " |-- SEV_Index_100: double (nullable = true)\n",
      " |-- SEV_Index_200: double (nullable = true)\n",
      " |-- VOLCADURA_100: integer (nullable = true)\n",
      " |-- VOLCADURA_200: integer (nullable = true)\n",
      " |-- SINIESTRO: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:39.861544Z",
     "start_time": "2019-08-03T17:35:39.831836Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:42.947000Z",
     "start_time": "2019-08-03T17:35:42.889467Z"
    }
   },
   "outputs": [],
   "source": [
    "xgboost = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:48.144171Z",
     "start_time": "2019-08-03T17:35:45.319622Z"
    }
   },
   "outputs": [],
   "source": [
    "xgbModel = xgboost.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:49.206445Z",
     "start_time": "2019-08-03T17:35:48.908314Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = xgbModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:50.986167Z",
     "start_time": "2019-08-03T17:35:50.180011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id|label|prediction|\n",
      "+---+-----+----------+\n",
      "|  0|  0.0|       0.0|\n",
      "|  3|  0.0|       0.0|\n",
      "| 14|  0.0|       0.0|\n",
      "| 18|  0.0|       0.0|\n",
      "| 23|  0.0|       0.0|\n",
      "+---+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('id', 'label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:54.686254Z",
     "start_time": "2019-08-03T17:35:54.677017Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:35:57.589117Z",
     "start_time": "2019-08-03T17:35:55.803866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.210117\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Almost same as Test Error (0.212002) got with GBT Default parameters.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T17:37:42.371546Z",
     "start_time": "2019-08-03T17:37:42.366637Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
